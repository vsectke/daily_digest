#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Daily News Digest System
Collects news from RSS feeds and sends email summary
"""

import os
import sys
import feedparser
import requests
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from bs4 import BeautifulSoup
import re
import time

print("üöÄ Kh·ªüi ƒë·ªông Daily News Digest System...")
print(f"üêç Python version: {sys.version}")
print(f"‚è∞ Th·ªùi gian: {datetime.now()}")

# Danh s√°ch RSS feeds theo ch·ªß ƒë·ªÅ
RSS_FEEDS = {
    "PCCC": [
        "https://baochinhphu.vn/rss/thoi-su.rss",
        "https://cand.com.vn/rss"
    ],
    "LNG": [
        "https://vnexpress.net/rss/kinh-doanh.rss", 
        "https://nangluongquocte.petrotimes.vn/rss"
    ],
    "MRT": [
        "https://tuoitre.vn/rss/thoi-su.rss",
        "https://vnexpress.net/rss/thoi-su.rss"
    ]
}

# User agent ƒë·ªÉ tr√°nh b·ªã block
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

def clean_text(text):
    """L√†m s·∫°ch text t·ª´ HTML"""
    if not text:
        return ""
    
    # Lo·∫°i b·ªè HTML tags
    soup = BeautifulSoup(text, 'html.parser')
    text = soup.get_text()
    
    # L√†m s·∫°ch whitespace
    text = re.sub(r'\s+', ' ', text.strip())
    
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt
    text = re.sub(r'[^\w\s.,!?;:()\-""''‚Ä¶]', '', text)
    
    return text

def extract_content_from_html(html_content, url):
    """Tr√≠ch xu·∫•t n·ªôi dung ch√≠nh t·ª´ HTML"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Lo·∫°i b·ªè c√°c ph·∫ßn kh√¥ng c·∫ßn thi·∫øt
        for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'menu']):
            tag.decompose()
        
        # T√¨m content ch√≠nh theo c√°c pattern ph·ªï bi·∫øn
        selectors = [
            'article',
            '[class*="content"]', 
            '[class*="article"]',
            '[class*="post"]',
            '[class*="story"]',
            '[id*="content"]',
            '[id*="article"]',
            '.main-content',
            '.entry-content',
            '.post-content'
        ]
        
        content_text = ""
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                content_text = " ".join([elem.get_text() for elem in elements])
                break
        
        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c selector c·ª• th·ªÉ, l·∫•y to√†n b·ªô body
        if not content_text:
            body = soup.find('body')
            if body:
                content_text = body.get_text()
            else:
                content_text = soup.get_text()
        
        # L√†m s·∫°ch v√† c·∫Øt ng·∫Øn
        content_text = clean_text(content_text)
        
        return content_text[:3000] if content_text else ""
        
    except Exception as e:
        print(f"    ‚ö†Ô∏è L·ªói parse HTML: {e}")
        return ""

def fetch_article_content(url, max_retries=2):
    """L·∫•y n·ªôi dung b√†i b√°o t·ª´ URL"""
    for attempt in range(max_retries):
        try:
            print(f"    üåê Fetching: {url[:80]}...")
            
            response = requests.get(
                url, 
                headers=HEADERS, 
                timeout=15,
                allow_redirects=True
            )
            response.raise_for_status()
            
            # Auto-detect encoding
            if response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding or 'utf-8'
            
            content = extract_content_from_html(response.text, url)
            
            if len(content) > 100:  # C√≥ n·ªôi dung h·ª£p l·ªá
                print(f"    ‚úÖ L·∫•y ƒë∆∞·ª£c {len(content)} k√Ω t·ª±")
                return content
            else:
                print(f"    ‚ö†Ô∏è N·ªôi dung qu√° ng·∫Øn ({len(content)} k√Ω t·ª±)")
                return ""
                
        except requests.exceptions.Timeout:
            print(f"    ‚ö†Ô∏è Timeout attempt {attempt+1}/{max_retries}")
            if attempt < max_retries - 1:
                time.sleep(2)
            continue
            
        except requests.exceptions.RequestException as e:
            print(f"    ‚ö†Ô∏è Request error: {str(e)[:100]}")
            return ""
            
        except Exception as e:
            print(f"    ‚ö†Ô∏è Unexpected error: {str(e)[:100]}")
            return ""
    
    return ""

def get_rss_description(entry):
    """L·∫•y m√¥ t·∫£ t·ª´ RSS entry"""
    description = ""
    
    # Th·ª≠ c√°c tr∆∞·ªùng kh√°c nhau
    for field in ['description', 'summary', 'content']:
        if hasattr(entry, field):
            content = getattr(entry, field)
            
            if isinstance(content, list) and content:
                # Tr∆∞·ªùng h·ª£p content l√† list (nh∆∞ feedparser)
                description = content[0].get('value', '') if isinstance(content[0], dict) else str(content[0])
            elif isinstance(content, str):
                description = content
            
            if description:
                break
    
    if description:
        description = clean_text(description)
        return description[:1500]
    
    return ""

def summarize_with_deepseek(content, title=""):
    """T√≥m t·∫Øt n·ªôi dung b·∫±ng DeepSeek API"""
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        return "‚ö†Ô∏è Thi·∫øu DEEPSEEK_API_KEY"
    
    if not content or len(content.strip()) < 50:
        return "‚ö†Ô∏è N·ªôi dung qu√° ng·∫Øn ƒë·ªÉ t√≥m t·∫Øt"

    try:
        # T·∫°o prompt context
        prompt_text = f"Ti√™u ƒë·ªÅ: {title}\n\nN·ªôi dung: {content[:2000]}"  # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh token limit
        
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system", 
                        "content": "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch tin t·ª©c Vi·ªát Nam v·ªÅ PCCC (ph√≤ng ch√°y ch·ªØa ch√°y), nƒÉng l∆∞·ª£ng LNG, v√† giao th√¥ng MRT. T√≥m t·∫Øt tin t·ª©c ng·∫Øn g·ªçn, ch√≠nh x√°c b·∫±ng ti·∫øng Vi·ªát."
                    },
                    {
                        "role": "user", 
                        "content": f"H√£y t√≥m t·∫Øt tin t·ª©c n√†y trong 2-3 c√¢u, t·∫≠p trung v√†o th√¥ng tin quan tr·ªçng:\n\n{prompt_text}"
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 200,
                "top_p": 0.9
            },
            timeout=30
        )
        
        response.raise_for_status()
        result = response.json()
        
        if 'choices' in result and result['choices'] and 'message' in result['choices'][0]:
            summary = result['choices'][0]['message']['content'].strip()
            return summary if summary else "‚ö†Ô∏è AI kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£"
        else:
            return "‚ö†Ô∏è Ph·∫£n h·ªìi API kh√¥ng h·ª£p l·ªá"
            
    except requests.exceptions.Timeout:
        return "‚ö†Ô∏è Timeout khi g·ªçi DeepSeek API"
    except requests.exceptions.RequestException as e:
        return f"‚ö†Ô∏è L·ªói API: {str(e)[:80]}"
    except Exception as e:
        return f"‚ö†Ô∏è L·ªói: {str(e)[:80]}"

def process_rss_feed(feed_url, topic, max_articles=3):
    """X·ª≠ l√Ω m·ªôt RSS feed"""
    articles = []
    
    try:
        print(f"  üì° ƒêang x·ª≠ l√Ω: {feed_url}")
        
        # Parse RSS
        feed = feedparser.parse(feed_url)
        
        if not feed.entries:
            print(f"  ‚ùå Kh√¥ng c√≥ b√†i vi·∫øt n√†o")
            return articles
        
        print(f"  üì∞ T√¨m th·∫•y {len(feed.entries)} b√†i vi·∫øt, x·ª≠ l√Ω {min(max_articles, len(feed.entries))} b√†i")
        
        for i, entry in enumerate(feed.entries[:max_articles]):
            print(f"\n    üìÑ [{i+1}/{max_articles}] {entry.title[:60]}...")
            
            # L·∫•y n·ªôi dung full t·ª´ link
            full_content = ""
            if hasattr(entry, 'link') and entry.link:
                full_content = fetch_article_content(entry.link)
            
            # N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c full content, d√πng description t·ª´ RSS
            if not full_content:
                full_content = get_rss_description(entry)
                print(f"    üìù S·ª≠ d·ª•ng RSS description: {len(full_content)} k√Ω t·ª±")
            
            if not full_content:
                print(f"    ‚ùå Kh√¥ng c√≥ n·ªôi dung")
                continue
            
            # T√≥m t·∫Øt b·∫±ng AI
            print(f"    ü§ñ ƒêang t√≥m t·∫Øt...")
            summary = summarize_with_deepseek(full_content, entry.title)
            
            # L∆∞u th√¥ng tin b√†i vi·∫øt
            article_info = {
                "title": getattr(entry, 'title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ'),
                "link": getattr(entry, 'link', ''),
                "summary": summary,
                "published": getattr(entry, 'published', ''),
                "content_length": len(full_content)
            }
            
            articles.append(article_info)
            print(f"    ‚úÖ Ho√†n th√†nh b√†i {i+1}")
            
            # Delay ƒë·ªÉ tr√°nh overload
            time.sleep(1)
        
    except Exception as e:
        print(f"  ‚ùå L·ªói x·ª≠ l√Ω feed: {e}")
    
    return articles

def collect_all_news():
    """Thu th·∫≠p tin t·ª©c t·ª´ t·∫•t c·∫£ RSS feeds"""
    all_news = {}
    total_articles = 0
    
    print(f"\nüîÑ B·∫Øt ƒë·∫ßu thu th·∫≠p tin t·ª©c t·ª´ {len(RSS_FEEDS)} ch·ªß ƒë·ªÅ...")
    
    for topic, feed_urls in RSS_FEEDS.items():
        print(f"\nüìö CHUY√äN M·ª§C: {topic}")
        print("=" * 40)
        
        all_news[topic] = []
        
        for feed_url in feed_urls:
            articles = process_rss_feed(feed_url, topic, max_articles=3)
            all_news[topic].extend(articles)
            total_articles += len(articles)
            
            # Ngh·ªâ gi·ªØa c√°c feed
            time.sleep(2)
        
        print(f"  üìä T·ªïng {topic}: {len(all_news[topic])} b√†i")
    
    print(f"\nüìà T·ªîNG K·∫æT: {total_articles} b√†i vi·∫øt t·ª´ {len(RSS_FEEDS)} chuy√™n m·ª•c")
    return all_news

def generate_email_content(news_data):
    """T·∫°o n·ªôi dung email"""
    today = datetime.now()
    date_str = today.strftime("%Y-%m-%d")
    time_str = today.strftime("%H:%M:%S")
    
    total_count = sum(len(articles) for articles in news_data.values())
    
    # Subject
    subject = f"[B·∫¢N TIN] PCCC¬∑LNG¬∑MRT ‚Äî {date_str} ({total_count} tin)"
    
    # Body header
    body = f"""üì∞ B·∫¢N TIN T·ª∞ ƒê·ªòNG H√ÄNG NG√ÄY
üìÖ Ng√†y: {date_str}
‚è∞ T·∫°o l√∫c: {time_str}
üìä T·ªïng s·ªë: {total_count} tin t·ª©c
{'='*60}

"""
    
    # Content cho t·ª´ng chuy√™n m·ª•c
    for topic, articles in news_data.items():
        if not articles:
            continue
            
        body += f"\nüè∑Ô∏è  {topic} ({len(articles)} tin)\n"
        body += "‚îÄ" * 50 + "\n\n"
        
        for i, article in enumerate(articles, 1):
            body += f"{i}. {article['title']}\n"
            
            if article['link']:
                body += f"üîó {article['link']}\n"
            
            if article['published']:
                body += f"üìÖ {article['published']}\n"
            
            body += f"üìù T√≥m t·∫Øt: {article['summary']}\n"
            body += f"üìè ƒê·ªô d√†i: {article['content_length']} k√Ω t·ª±\n"
            body += "\n" + "¬∑" * 40 + "\n\n"
    
    # Footer
    body += f"""
{'='*60}
ü§ñ H·ªá th·ªëng Daily Digest t·ª± ƒë·ªông
üîÑ L·∫ßn ch·∫°y ti·∫øp theo: Ng√†y mai 08:00
‚öôÔ∏è Phi√™n b·∫£n: 2.0 (No newspaper3k)
"""
    
    return subject, body

def send_daily_email(news_data):
    """G·ª≠i email b√°o c√°o h√†ng ng√†y"""
    
    # Ki·ªÉm tra c·∫•u h√¨nh SMTP
    smtp_config = {
        'host': os.getenv("SMTP_HOST", "smtp.gmail.com"),
        'port': int(os.getenv("SMTP_PORT", "587")),
        'user': os.getenv("SMTP_USER"),
        'pass': os.getenv("SMTP_PASS"),
        'to': os.getenv("EMAIL_TO")
    }
    
    missing_config = [k for k, v in smtp_config.items() if k != 'host' and k != 'port' and not v]
    if missing_config:
        print(f"‚ùå Thi·∫øu c·∫•u h√¨nh email: {missing_config}")
        return False
    
    try:
        # T·∫°o n·ªôi dung email
        subject, body = generate_email_content(news_data)
        
        # T·∫°o message
        msg = MIMEMultipart()
        msg['From'] = smtp_config['user']
        msg['To'] = smtp_config['to']
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        # G·ª≠i email
        print("üìß ƒêang k·∫øt n·ªëi SMTP server...")
        with smtplib.SMTP(smtp_config['host'], smtp_config['port']) as server:
            server.starttls()
            server.login(smtp_config['user'], smtp_config['pass'])
            server.send_message(msg)
        
        print("‚úÖ Email ƒë√£ ƒë∆∞·ª£c g·ª≠i th√†nh c√¥ng!")
        print(f"üì¨ G·ª≠i t·ªõi: {smtp_config['to']}")
        print(f"üìã Ti√™u ƒë·ªÅ: {subject}")
        return True
        
    except smtplib.SMTPAuthenticationError:
        print("‚ùå L·ªói x√°c th·ª±c SMTP - ki·ªÉm tra username/password")
        return False
    except smtplib.SMTPException as e:
        print(f"‚ùå L·ªói SMTP: {e}")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói g·ª≠i email: {e}")
        return False

def main():
    """H√†m ch√≠nh c·ªßa ch∆∞∆°ng tr√¨nh"""
    print("üöÄ DAILY NEWS DIGEST SYSTEM v2.0")
    print(f"‚è∞ Kh·ªüi ƒë·ªông: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("üîß Kh√¥ng s·ª≠ d·ª•ng newspaper3k")
    print("="*60)
    
    try:
        # B∆∞·ªõc 1: Thu th·∫≠p tin t·ª©c
        print("\nüì° B∆Ø·ªöC 1: THU TH·∫¨P TIN T·ª®C")
        news_data = collect_all_news()
        
        # B∆∞·ªõc 2: Ki·ªÉm tra k·∫øt qu·∫£
        total_news = sum(len(articles) for articles in news_data.values())
        
        if total_news == 0:
            print("\n‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c tin t·ª©c n√†o!")
            print("C√≥ th·ªÉ nguy√™n nh√¢n:")
            print("- RSS feeds kh√¥ng kh·∫£ d·ª•ng")
            print("- K·∫øt n·ªëi m·∫°ng k√©m")  
            print("- Website ch·∫∑n requests")
            print("- L·ªói API DeepSeek")
            return False
        
        print(f"\n‚úÖ Thu th·∫≠p th√†nh c√¥ng {total_news} tin t·ª©c!")
        
        # B∆∞·ªõc 3: G·ª≠i email
        print("\nüìß B∆Ø·ªöC 2: G·ª¨I EMAIL")
        success = send_daily_email(news_data)
        
        if success:
            print("\nüéâ HO√ÄN TH√ÄNH TH√ÄNH C√îNG!")
            print(f"üìä ƒê√£ x·ª≠ l√Ω: {total_news} tin t·ª©c")
            print(f"‚è∞ Th·ªùi gian th·ª±c hi·ªán: {datetime.now()}")
            return True
        else:
            print("\nüí• TH·∫§T B·∫†I KHI G·ª¨I EMAIL!")
            return False
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Ch∆∞∆°ng tr√¨nh b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        return False
    except Exception as e:
        print(f"\nüí• L·ªñI NGHI√äM TR·ªåNG: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
